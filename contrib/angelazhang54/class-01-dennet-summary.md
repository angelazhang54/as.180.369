# Reaction to Dennet Article

In the article from the Atlantic “The Problem With Counterfeit People”, by Daniel C. Dennet, the author makes an argument about how companies using artificial intelligence to generate fake people are committing an immoral act and should be responsible for their actions. Given the advancement of artificial intelligence today, it is now possible to make counterfeit people that can pass as real people. These counterfeits are extremely dangerous to society, because they give powerful corporate and political organizations the ability to interfere with our judgement through manipulative conversations, exploiting people's fears, or other actions that make people more vulnerable. People would lose their ability to reason for themselves. It also erodes trust between people, as it may soon be impossible to tell whether the “person” you are interacting with is actually a human being. A big danger about this system is that artificial intelligence can learn from each other and reproduce to make themselves better. This can possibly take the control of these systems out of the developer’s own hands, and by then it will be too late to try to shut it down. Therefore, it is essential that companies start to adopt preventive measures, such as a "watermark" system to label what is an AI product, before things get out of hand. This watermark system is extremely hard and costly for anyone, including all corporations and the government, to try to overpower, so it would be able to protect the system relatively well. A set of laws punishing creators of counterfeit people is also critical and a very effective way to help protect our freedom and humanity, as making sure companies that produce artificial intelligence products are held responsible for their developments would keep companies in line and enhance the safety of the consumers. Companies should be able to enjoy the rewards of their developments but also be prepared to be fined or go to jail if it fails to meet the ethical obligations for use of artificial intelligence. The article ends by saying although artificial intelligence is already deeply rooted in our lives due to all the platform algorithms online, we can still try to save our freedom to think by regulating developers of artificial intelligence products.

I believe this can turn out to be a potentially terrifying situation if left unregulated. It could rob us of our future and freedom to reason, and the public would become passive about the world around them. It is critical that there be a way people can tell between what is an artificial intelligence product and what is not. Given how highly-funded and the rapid advancement of the artificial intelligence industry, the best way to this this would be to place liabilities on the developers to make sure they are using artificial intelligence in an ethical way. This could be the only way to keep our freedom of thought before all the algorithms and fake people get to us and we are subconsciously manipulated into accepting policies and ideas of the controllers. 
